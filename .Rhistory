df_c = hclust(dist(df),method="average")
plot(df_c,cex=0.2)
df_c = hclust(dist(df),method="single")
plot(df_c,,cex=0.2)
df = mxp_Data(5000,3,20,2)
mtry = mtry = floor(sqrt(23))
DF = Class_Mod(df,K,mtry)
g1  = plot_graph(DF,"nObs-5000, mtry=2")
library(randomForest)
library(MASS)
library(class)
library(ggplot2)
library(grid)
library(gridExtra)
library(caret)
mxp_Data = function(nObs =50, nClassVars=2,nNoiseVars=3,deltaClass=1){
xyzTmp <- matrix(rnorm(nObs*(nClassVars+nNoiseVars)),
nrow = nObs,ncol= nClassVars+nNoiseVars)
classTmp <- 1
for (iTmp in 1:nClassVars){
deltaTmp <- sample(deltaClass*c(-1,1),nObs,replace = TRUE )
xyzTmp[,iTmp] <- xyzTmp[,iTmp] + deltaTmp
classTmp <- classTmp * deltaTmp
}
classTmp <- factor(classTmp > 0)
df = data.frame(cbind(xyzTmp, classTmp))
df$classTmp = as.factor(df$classTmp)
return(df)
}
```
The above function takes four input variables, namely number of observation (nObs),nos of predictors associated with outcome (nClassVars), predictors not associated with outcome (nNoiseVars), Average difference between two classes' (deltaClass)
```{r}
Class_Mod = function(data =df, Ktry,mtry){
dtrain <- sample(1:nrow(data),0.5*nrow(data))
training <- data[dtrain,]
test <- data[-dtrain,]
dim(training)
dim(test)
# Random forest
data = NULL
rf_mdl = randomForest( classTmp~., data= training, method ="rf", mtry = mtry )
pred = predict(rf_mdl, newdata= test)
confMatrix_RD = confusionMatrix(test$classTmp,pred)
Acc = c(1- confMatrix_RD$overall[1],
confMatrix_RD$byClass[1],
confMatrix_RD$byClass[2]);
stats= c("TestErrorRate","Sensitivity","Specificity")
Model = c("Random_Forest")
DF = data.frame(Acc, stats,Model)
#LDA forest
lda.fit = train(classTmp~., data= training, method="lda")
pred_lda = predict(lda.fit, newdata = test)
lda_err = 1- confusionMatrix(test$classTmp,pred_lda)$overall[1]
confMatrix_LDA = confusionMatrix(test$classTmp,pred_lda)
Acc = c(1- confMatrix_LDA$overall[1],
confMatrix_LDA$byClass[1],
confMatrix_LDA$byClass[2]);
stats= c("TestErrorRate","Sensitivity","Specificity")
Model = c("LDA")
DF = rbind(DF,data.frame(Acc, stats,Model))
#KNN model
library(FNN)
dfTmp <- NULL
n= dim(training)[2]
for ( kTmp in Ktry) {
x_train = training[,-n]
x_test = test[,-n]
Y_train = training$classTmp
Y_test = test$classTmp
knn.pred = knn(x_train,x_test,Y_train , k= kTmp )
confMatrix_KNN = confusionMatrix(knn.pred, Y_test)
Acc = c(1- confMatrix_KNN$overall[1],
confMatrix_KNN$byClass[1],
confMatrix_KNN$byClass[2]);
stats= c("TestErrorRate","Sensitivity","Specificity")
Model = c(paste0("KNN_",kTmp))
DF = rbind(DF,data.frame(Acc, stats,Model))
}
return(DF)
}
```
The above function perform LDA, Random Forest and KNN on the simulated datasets.
```{r}
plot_graph = function(Data,ptitle= "KNN error Rate"){
library(ggplot2)
dfTmp = DF[DF$stats =="TestErrorRate",]
rflda = dfTmp[1:2,]
dfTmp =dfTmp[-c(1,2),]
g= ggplot(dfTmp,aes(x=1:nrow(dfTmp),y=Acc)) + geom_point() +
scale_x_log10() +  geom_hline(aes(yintercept =Acc,colour =Model),
data=rflda) +
labs(title = ptitle,
x= "K nearest neigbour",y="Test Error Rate")
g
}
set.seed(200)
df = mxp_Data(5000,3,20,2)
mtry = mtry = floor(sqrt(23))
DF = Class_Mod(df,K,mtry)
g1  = plot_graph(DF,"nObs-5000, mtry=2")
K= c(floor(1.2^(1:33)))
set.seed(200)
df = mxp_Data(5000,3,20,2)
mtry = mtry = floor(sqrt(23))
DF = Class_Mod(df,K,mtry)
g1  = plot_graph(DF,"nObs-5000, mtry=2")
g1
dtrain <- sample(1:nrow(df),0.5*nrow(df))
training <- df[dtrain,]
test <- df[-dtrain,]
floor(sqrt(23))
rf_mdl = randomForest( classTmp~., data= training, method ="rf", mtry = mtry )
pred = predict(rf_mdl, newdata= test)
confMatrix_RD = confusionMatrix(test$classTmp,pred)
Acc = c(1- confMatrix_RD$overall[1],
confMatrix_RD$byClass[1],
confMatrix_RD$byClass[2]);
stats= c("TestErrorRate")
Model = c("mtry_3")
DF = rbind(DF,data.frame(Acc, stats,Model))
DF
mtry = c(2,5,10)
for (i in mtry){
rf_mdl = randomForest( classTmp~., data= training, method ="rf", mtry = mtry )
pred = predict(rf_mdl, newdata= test)
confMatrix_RD = confusionMatrix(test$classTmp,pred)
Acc = c(1- confMatrix_RD$overall[1],
confMatrix_RD$byClass[1],
confMatrix_RD$byClass[2]);
stats= c("TestErrorRate")
Model = c("mtry_3")
DF = rbind(DF,data.frame(Acc, stats,Model))
}
DF
set.seed(200)
df = mxp_Data(5000,3,20,2)
mtry  = floor(sqrt(23))
DF = Class_Mod(df,K,mtry)
dtrain <- sample(1:nrow(df),0.5*nrow(df))
training <- df[dtrain,]
test <- df[-dtrain,]
mtry = c(2,5,10)
for (i in mtry){
rf_mdl = randomForest( classTmp~., data= training, method ="rf", mtry = mtry )
pred = predict(rf_mdl, newdata= test)
confMatrix_RD = confusionMatrix(test$classTmp,pred)
Acc = c(1- confMatrix_RD$overall[1])
stats= c("TestErrorRate")
Model = c(paste0("mtry_",i))
DF = rbind(data.frame(Acc, stats,Model),DF)
}
DF
dfTmp = DF[DF$stats =="TestErrorRate",]
dfTmp
dfTmp = DF[DF$stats =="TestErrorRate",]
rflda = dfTmp[1:5,]
dfTmp =dfTmp[-c(1:5),]
g= ggplot(dfTmp,aes(x=1:nrow(dfTmp),y=Acc)) + geom_point() +
scale_x_log10() +  geom_hline(aes(yintercept =Acc,colour =Model),
data=rflda) +
labs(title = ptitle,
x= "K nearest neigbour",y="Test Error Rate")
g
dfTmp = DF[DF$stats =="TestErrorRate",]
rflda = dfTmp[1:5,]
dfTmp =dfTmp[-c(1:5),]
g= ggplot(dfTmp,aes(x=1:nrow(dfTmp),y=Acc)) + geom_point() +
scale_x_log10() +  geom_hline(aes(yintercept =Acc,colour =Model),
data=rflda) +
labs(title = "t",
x= "K nearest neigbour",y="Test Error Rate")
g
set.seed(200)
df = mxp_Data(5000,3,20,2)
mtry  = floor(sqrt(23))
DF = NULL
DF = Class_Mod(df,K,mtry)
dtrain <- sample(1:nrow(df),0.5*nrow(df))
training <- df[dtrain,]
test <- df[-dtrain,]
mtry = c(2,5,10,23)
for (i in mtry){
rf_mdl = randomForest( classTmp~., data= training, method ="rf", mtry = mtry )
pred = predict(rf_mdl, newdata= test)
confMatrix_RD = confusionMatrix(test$classTmp,pred)
Acc = c(1- confMatrix_RD$overall[1])
stats= c("TestErrorRate")
Model = c(paste0("mtry_",i))
DF = rbind(data.frame(Acc, stats,Model),DF)
}
dfTmp = DF[DF$stats =="TestErrorRate",]
rflda = dfTmp[c(1,2,3,5),]
dfTmp =dfTmp[-c(1,2,3,5),]
g= ggplot(dfTmp,aes(x=1:nrow(dfTmp),y=Acc)) + geom_point() +
scale_x_log10() +  geom_hline(aes(yintercept =Acc,colour =Model),
data=rflda) +
labs(x= "K nearest neigbour",y="Test Error Rate")
g
mtry = c(2,5,10)
install.packages("neuralnet")
install.packages("neuralnet")
library(neuralnet)
dim(infert)
head(infert)
?infert
pairs(infert)
pairs(infert, col=infert$case +1)
Log_mod = glm( ~ Variance + Skewness + Curtosis + Entropy,
data = banknote,family="binomial" )
head(iris)
Log_mod = glm(species ~ .,
data = iris,family="binomial" )
Log_mod = glm(Species ~ .,
data = iris,family="binomial" )
Log_mod
pred = predict(Log_mod,newdata = iris)
pred
nObs <- 1000
xyTmp <- matrix(rnorm(4*nObs),ncol=2)
xyTmp
lenfth(xyTmp)
length(xyTmp)
dim(xyTmp)
xyTmp <- matrix(rnorm(3*nObs),ncol=3)
dim(xyTmp)
head(xyTmp)
matrix(sample(c(-1,1)*ctrPos,nObs*3,replace=TRUE),ncol=2)
cl = numeric(1000)
nObs <- 1000
ctrPos <- 2
xyTmp <- matrix(rnorm(4*nObs),ncol=2)
xyCtrsTmp <- matrix(sample(c(-1,1)*ctrPos,nObs*4,replace=TRUE),ncol=2)
xyTmp <- xyTmp + xyCtrsTmp
gTmp <- paste0("class",(1+sign(apply(xyCtrsTmp,1,prod)))/2)
xyTmp
head(xyTmp)
data.frame(g=as.numeric(factor(gTmp)),xyTmp)
p=data.frame(g=as.numeric(factor(gTmp)),xyTmp)
head(p)
p= data.frame(xyTmp)
head(p)
nObs <- 1000
ctrPos <- 2
xyTmp <- matrix(rnorm(3*nObs),ncol=3)
p= data.frame(xyTmp)
head(p)
cl[X1^2 + X2^2 + X3^3 < 1.5]=1
cl = numeric(1000)
cl[p$X1^2 + p$X2^2 + p$X3^3 < 1.5]= 1
cl
xyTmp[1]
xyTmp
,
xyTmp[,1]
xyTmp[1,]
head(xyTemp)
head(xyTmp)
head(xyTmp[,1])
cl = numeric(1000)
cl[xyTmp[,1]^2 + xyTmp[,2]^2 + xyTmp[,3]^3 < 1.5]= 1
Df = data.frame(factor(cl),xyTmp)
head(Df)
Df = data.frame(cl =factor(cl),xyTmp)
plot(xyTmp,col=as.numeric(factor(cl),pch=as.numeric(factor(ck)),
xlab="X1",ylab="X2")
plot(xyTmp,col=as.numeric(factor(cl),
pch=as.numeric(factor(cl),
xlab="X1",ylab="X2")
plot(xyTmp,col=as.numeric(factor(cl),
pch=as.numeric(factor(cl),
xlab="X1",ylab="X2")
)
))
plot(xyTmp,col=as.numeric(factor(cl),
pch=as.numeric(factor(cl)),
xlab="X1",ylab="X2")
)))
plot(xyTmp,col=as.numeric(factor(cl)),
pch=as.numeric(factor(cl)),
xlab="X1",ylab="X2")
library(scatterplot3d)
library(scatterplot3d)
scatterplot3d(Df)
head(df)
head(Df)
library(plotly)
install.packages(ploty)
install.packages(plotly)
install.packages("plotly")
library(plotly)
plot_ly(Df, x=~X1,y=~X2,z=~X3, color=~cl,color('red','blue'))%>%
add_markers()%>%
layout(scene=list(xaxis=list(title="X1"),
yaxis=list(title='X2'),
zaxis= list(title='X3')))
plot_ly(Df, x=~X1,y=~X2,z=~X3, color=~cl,colors=c('red','blue'))%>%
add_markers()%>%
layout(scene=list(xaxis=list(title="X1"),
yaxis=list(title='X2'),
zaxis= list(title='X3')))
matrix(sample(c(-1,1)*ctrPos,nObs*3,replace=TRUE),ncol=2)
xyTmp <- xyTmp + xyCtrsTmp
plot(xyTmp,col=as.numeric(factor(cl)),
pch=as.numeric(factor(cl)),
xlab="X1",ylab="X2")
plot(xyTmp,col=as.numeric(factor(cl)),
pch=19,
xlab="X1",ylab="X2")
plot(xyTmp[,1:2],col=as.numeric(factor(cl)),
pch=19,
xlab="X1",ylab="X2")
plot(xyTmp[,2:3],col=as.numeric(factor(cl)),
pch=19,
xlab="X1",ylab="X2")
plot_ly(Df, x=~X1,y=~X2,z=~X3, color=~cl,colors=c('red','blue'))%>%
add_markers()%>%
layout(scene=list(xaxis=list(title="X1"),
yaxis=list(title='X2'),
zaxis= list(title='X3')))
xyTmp <- matrix(rnorm(2*50),ncol=2)
cl[xyTmp[,1]^2 + xyTmp[,2]^2  < 1]= 1
cl =numeric(50)
cl[xyTmp[,1]^2 + xyTmp[,2]^2  < 1]= 1
plot(xyTmp )
plot(xyTmp , col=numeric(factor(cl)))
plot(xyTmp , col=numeric(as.factor(cl))+1)
numeric(as.factor(cl)
)
as.factor(cl)
plot(xyTmp , col=as.factor(cl))+1)
plot(xyTmp , col=as.factor(cl)+1)
plot(xyTmp , col=as.factor(cl))
xyTmp <- matrix(rnorm(2*500),ncol=2)
cl =numeric(500)a
cl[xyTmp[,1]^2 + xyTmp[,2]^2  < 1]= 1
plot(xyTmp , col=as.factor(cl))
abline(v=0)
abline(h=0)
abline(h=-1)
nObs <- 1000
ctrPos <- 2
xyTmp <- matrix(rnorm(3*nObs),ncol=3)
p= data.frame(xyTmp)
cl = numeric(1000)
cl[xyTmp[,1]^2 + xyTmp[,2]^2 + xyTmp[,3]^3 < 1.5]= 1
Df = data.frame(cl =factor(cl),xyTmp)
plot(xyTmp[,2:3],col=as.numeric(factor(cl)),
pch=19,
xlab="X1",ylab="X2")
plot_ly(Df, x=~X1,y=~X2,z=~X3, color=~cl,colors=c('red','blue'))%>%
add_markers()%>%
layout(scene=list(xaxis=list(title="X1"),
yaxis=list(title='X2'),
zaxis= list(title='X3')))
plot_ly(Df, x=~X1,y=~X2,z=~X3, color=~cl)%>%
add_markers()%>%
layout(scene=list(xaxis=list(title="X1"),
yaxis=list(title='X2'),
zaxis= list(title='X3')))
install.packages("rgl")
spheres3d(0,0,0,lit=FALSE,color="white")
library("rgl")
library(rgl)
library(rgl)
library("ggl")
library("rgl")
sqrt(1.5)
1.5^2
matrix(sample(c(-1,1,-1)*ctrPos,nObs*3,replace=TRUE),ncol=3)
xyTmp <- matrix(rnorm(3*nObs, mean =0,sd = 3),ncol=3)
xyCtrsTmp <- matrix(sample(c(-1,1,-1)*1.5,nObs*3,replace=TRUE),ncol=3)
xyTmp
xyTmp <- xyTmp + xyCtrsTmp
cl[xyTmp[,1]^2 + xyTmp[,2]^2 + xyTmp[,3]^3 < (1.5)^2]= 1
Df = data.frame(cl =factor(cl),xyTmp)
plot(xyTmp[,2:3],col=as.numeric(factor(cl)),
pch=19,
xlab="X1",ylab="X2")
plot(xyTmp[,1:2],col=as.numeric(factor(cl)),
pch=19,
xlab="X1",ylab="X2")
xyTmp <- matrix(rnorm(3*nObs, mean =0,sd = 3),ncol=3)
p= data.frame(xyTmp)
cl = numeric(1000)
cl[xyTmp[,1]^2 + xyTmp[,2]^2 + xyTmp[,3]^3 < (1.5)^2]= 1
Df = data.frame(cl =factor(cl),xyTmp)
plot(xyTmp[,1:2],col=as.numeric(factor(cl)),
pch=19,
xlab="X1",ylab="X2")
library(plotly)
plot_ly(Df, x=~X1,y=~X2,z=~X3, color=~cl)%>%
add_markers()%>%
layout(scene=list(xaxis=list(title="X1"),
yaxis=list(title='X2'),
zaxis= list(title='X3')))
library("rgl", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
detach("package:rgl", unload=TRUE)
library(scatterplot3d)
sp= scatterplot3d(Df$X1,Df$X2,Df$X3,color =cl+1,cex.symbols=0.8,
pch=19,angle=20)
sp$plane3d(1.5^2,0,0)
sp= scatterplot3d(Df$X1,Df$X2,Df$X3,color =cl+1,cex.symbols=0.8,
pch=19,angle=90)
sp= scatterplot3d(Df$X1,Df$X2,Df$X3,color =cl+1,cex.symbols=0.8,
pch=19,angle=40)
sp= scatterplot3d(Df$X1,Df$X2,Df$X3,color =cl+1,cex.symbols=0.8,
pch=19,angle=30)
sp$plane3d(1.5^2,0,0)
sp$plane3d(0,0,0)
sp= scatterplot3d(Df$X1,Df$X2,Df$X3,color =cl+1,cex.symbols=0.8,
pch=19,angle=30)
sp$plane3d(0,0,0)
sp= scatterplot3d(Df$X1,Df$X2,Df$X3,color =cl+1,cex.symbols=0.8,
pch=19,angle=110)
sp$plane3d(0,0,0)
sp= scatterplot3d(Df$X1,Df$X2,Df$X3,color =cl+1,cex.symbols=0.8,
pch=19,angle=180)
sp= scatterplot3d(Df$X1,Df$X2,Df$X3,color =cl+1,cex.symbols=0.8,
pch=19,angle=120)
sp= scatterplot3d(Df$X1,Df$X2,Df$X3,color =cl+1,cex.symbols=0.8,
pch=19,angle=150)
head(Df)
plot(Df$X1,Df$X2)
abline(v=0)
abline(h=0)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,color =cl+1,cex.symbols=0.8,
pch=19,angle=150)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,color =cl+1,cex.symbols=0.8,
pch=19,angle=20)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =cl,cex.symbols=0.8,
pch=19,angle=20)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =c('red',"grey"),cex.symbols=0.8,
pch=19,angle=20)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =c('red',"grey"),cex.symbols=0.8,
pch=19,angle=20)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =c(1,2),cex.symbols=0.8,
pch=19,angle=20)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =cl+1,cex.symbols=0.8,
pch=19,angle=20)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =c(2,3),cex.symbols=0.8,
pch=19,angle=20)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =cl+1,cex.symbols=0.8,
pch=19,angle=50)
sp$plane3d(0,0,0)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =cl+1,cex.symbols=0.8,
pch=19,angle=90)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =cl+1,cex.symbols=0.8,
pch=19,angle=180)
sp= scatterplot3d(Df$X1,Df$X2,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =cl+1,cex.symbols=0.8,
pch=19,angle=270)
sp= scatterplot3d(Df$X1,Df$X3,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =cl+1,cex.symbols=0.8,
pch=19,angle=270)
sp= scatterplot3d(Df$X1,Df$X3,(Df$X3^2 +Df$X1^2 +Df$X2^2) ,
color =cl+1,cex.symbols=0.8,
pch=19,angle=20)
df =data.frame(x1,x2,y)
df =data.frame(x1,x2,Y)
x1= c(0,1,1)
x2 = c(1,0,1)
Y= c(1,1,0)
df =data.frame(x1,x2,Y)
df
library(neuralnet)
pd= neuralnet(Y~x1+x2, df, err.fct = 'ce',linear.output = FALSE)
plot(pd)
pd= neuralnet(Y~x1+x2, df, err.fct = 'ce',linear.output = FALSE,hidden=0)
plot(pd)
compute(pd,data.frame(x1=0,x2=0))
pd= neuralnet(Y~x1+x2, df, err.fct = 'ce',linear.output = FALSE,hidden=0)
plot(pd)
compute(pd,data.frame(x1=0,x2=0))
pd= neuralnet(Y~x1+x2, df, err.fct = 'ce',linear.output = FALSE,hidden=0)
plot(pd)
compute(pd,data.frame(x1=0,x2=0))
pd= neuralnet(Y~x1+x2, df, err.fct = 'ce',linear.output = FALSE)
plot(pd)
compute(pd,data.frame(x1=0,x2=0))
library(caret)
setwd("~/Documents/HARVARD Studies/Fundamental of DataScience/project")
Emp.Attrition = read.csv("Employee-Attrition.csv")
head(Emp.Attrition,10)
summary(Emp.Attrition)
library(mosaic)
head(Emp.Attrition,10)
tally(~Attrition | Gender, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~Attrition | MartitialStatus, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~Attrition | MaritalStatus, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~Attrition | WorkLifeBalance, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~Attrition | OverTime, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~ OverTime, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~WorkLifeBalance, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~Attrition | JobLevel, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~ JobLevel|Attrition, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~Attrition | BusinessTravel, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally( BusinessTravel, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~ BusinessTravel, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~Attrition | Department, format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~ Department |Attrition , format = "proportion", data = Emp.Attrition, margins=TRUE)
summary(Emp.Attrition)
tally(~ StockOptionLevel |Attrition , format = "proportion", data = Emp.Attrition, margins=TRUE)
tally(~ Attrition |StockOptionLevel , format = "proportion", data = Emp.Attrition, margins=TRUE)
